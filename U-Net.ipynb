{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T17:45:13.088948Z",
     "iopub.status.busy": "2025-10-25T17:45:13.088756Z",
     "iopub.status.idle": "2025-10-25T17:45:13.093463Z",
     "shell.execute_reply": "2025-10-25T17:45:13.092726Z",
     "shell.execute_reply.started": "2025-10-25T17:45:13.088929Z"
    },
    "id": "EplPZB-ey0cZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms, io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-25T17:45:13.094933Z",
     "iopub.status.busy": "2025-10-25T17:45:13.094747Z",
     "iopub.status.idle": "2025-10-25T17:45:13.111556Z",
     "shell.execute_reply": "2025-10-25T17:45:13.110910Z",
     "shell.execute_reply.started": "2025-10-25T17:45:13.094918Z"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1761237829262,
     "user": {
      "displayName": "Lorenzo Bacchini",
      "userId": "02263551721512258842"
     },
     "user_tz": -120
    },
    "id": "MPQ-xSLK11lx",
    "outputId": "0f9b1bbb-89bb-44d4-e467-93217e4cdf2f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T17:45:13.112575Z",
     "iopub.status.busy": "2025-10-25T17:45:13.112332Z",
     "iopub.status.idle": "2025-10-25T17:45:13.126335Z",
     "shell.execute_reply": "2025-10-25T17:45:13.125450Z",
     "shell.execute_reply.started": "2025-10-25T17:45:13.112553Z"
    },
    "id": "sYDiX_tzNICI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In the cityscapes dataset only 19 labels are included in evaluation\n",
    "therefore i remapped the 34 original classes to 19, considering the remaining 15 as void\n",
    "as suggested by the dataset documentation\n",
    "'''\n",
    "\n",
    "'''\n",
    "Dictionary to encode the labels remapping\n",
    "'''\n",
    "label_to_trainid = {\n",
    "    7:0, 8:1, 11:2, 12:3, 13:4, 17:5, 19:6, 20:7, 21:8, 22:9,\n",
    "    23:10, 24:11, 25:12, 26:13, 27:14, 28:15, 31:16, 32:17, 33:18\n",
    "}\n",
    "\n",
    "'''\n",
    "Function that converts the dataset labels(34) to the training/testing labels(19)\n",
    "The original labels from 0-33 are remapped into 0-18 following the scheme at this link:\n",
    "https://github.com/mcordts/cityscapesScripts/blob/878f1d05b1676c669d977a91831ea800482e36c4/cityscapesscripts/helpers/labels.py#L62\n",
    "'''\n",
    "def convert_labelIds_to_trainIds(label_img):\n",
    "    label_copy = torch.full_like(label_img, 255, dtype=torch.long)\n",
    "    for k, v in label_to_trainid.items():\n",
    "        label_copy[label_img == k] = v\n",
    "    return label_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-Bcjo6LUs5Q"
   },
   "source": [
    "# Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T17:45:13.219056Z",
     "iopub.status.busy": "2025-10-25T17:45:13.218810Z",
     "iopub.status.idle": "2025-10-25T17:45:13.226311Z",
     "shell.execute_reply": "2025-10-25T17:45:13.225679Z",
     "shell.execute_reply.started": "2025-10-25T17:45:13.219038Z"
    },
    "id": "wcw_circW69S",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Custom dataset to retrieve the dataset image, coloured masks and labelIds masks\n",
    "coloured masks will be used only to obtain a visual feedback about the segmentation\n",
    "while labelIds masks will be used to train and test the network\n",
    "'''\n",
    "class CityscapeDataset(Dataset):\n",
    "    def __init__(self, root_path=\"./data\", test=False, image_transform=None, mask_transform=None):\n",
    "        self.root_path = Path(root_path)\n",
    "        self.mask_pattern = \"**/*_gtFine_color.png\"\n",
    "        self.labelIds_pattern = \"**/*_labelIds.png\"\n",
    "        self.image_pattern = \"**/*.png\"\n",
    "\n",
    "        if test:\n",
    "            self.images = sorted(self.root_path.joinpath(\"Cityscape Dataset/leftImg8bit/test\").glob(self.image_pattern))\n",
    "            self.masks = sorted(self.root_path.joinpath(\"Fine Annotations/gtFine/test\").glob(self.mask_pattern))\n",
    "            self.labelIds = sorted(self.root_path.joinpath(\"Fine Annotations/gtFine/test\").glob(self.labelIds_pattern))\n",
    "        else:\n",
    "            self.images = sorted(self.root_path.joinpath(\"Cityscape Dataset/leftImg8bit/train/\").glob(self.image_pattern))\n",
    "            self.masks = sorted(self.root_path.joinpath(\"Fine Annotations/gtFine/train/\").glob(self.mask_pattern))\n",
    "            self.labelIds = sorted(self.root_path.joinpath(\"Fine Annotations/gtFine/train\").glob(self.labelIds_pattern))\n",
    "\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.images[index]).convert('RGB') # Ensure image is in RGB\n",
    "        mask = Image.open(self.masks[index]).convert('RGB') # Load coloured mask as RGB\n",
    "        labelId = Image.open(self.labelIds[index]).convert('L') # Load labelId as grayscale\n",
    "\n",
    "\n",
    "        if self.image_transform:\n",
    "            img = self.image_transform(img)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "            labelId = self.mask_transform(labelId)\n",
    "\n",
    "        # dataset ids conversion to train ids\n",
    "        labelId = convert_labelIds_to_trainIds(labelId)\n",
    "\n",
    "        return img, mask, labelId\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8zg-MkufwfC"
   },
   "source": [
    "# Net definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_FqJpILNICR"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T17:45:13.227686Z",
     "iopub.status.busy": "2025-10-25T17:45:13.227457Z",
     "iopub.status.idle": "2025-10-25T17:45:13.243275Z",
     "shell.execute_reply": "2025-10-25T17:45:13.242621Z",
     "shell.execute_reply.started": "2025-10-25T17:45:13.227670Z"
    },
    "id": "qmgh5BYazNdy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_ch, n_filters=64, dropout_prob=0.3, max_pooling=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(in_ch, n_filters, kernel_size=3, padding='same')\n",
    "        self.conv_2 = nn.Conv2d(n_filters, n_filters, kernel_size=3, padding='same')\n",
    "        self.activation = nn.ReLU()\n",
    "        self.max_pooling = max_pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) if self.max_pooling else None\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.batch_norm = nn.BatchNorm2d(n_filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_1(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv_2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.batch_norm(out)\n",
    "        if self.dropout_prob > 0:\n",
    "            out = self.dropout(out)\n",
    "\n",
    "        skip_connection = out.clone()\n",
    "        if self.max_pooling:\n",
    "            next_layer = self.pool(out)\n",
    "        else:\n",
    "            next_layer = out\n",
    "\n",
    "        return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4vBLqkENICU"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T17:45:13.244343Z",
     "iopub.status.busy": "2025-10-25T17:45:13.243950Z",
     "iopub.status.idle": "2025-10-25T17:45:13.265326Z",
     "shell.execute_reply": "2025-10-25T17:45:13.264633Z",
     "shell.execute_reply.started": "2025-10-25T17:45:13.244325Z"
    },
    "id": "6pAm_SRl4dAf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class upsampling_block(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, n_filters=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = nn.ConvTranspose2d(in_ch, in_ch//2, kernel_size=2, stride=(2, 2), padding=0)\n",
    "        self.conv_1 = nn.Conv2d(in_ch//2 + skip_ch, n_filters, kernel_size=3, padding='same')\n",
    "        self.conv_2 = nn.Conv2d(n_filters, n_filters, kernel_size=3, padding='same')\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        conv = self.upsample(x)\n",
    "        conv = torch.cat([conv, skip], dim=1)\n",
    "        conv = self.conv_1(conv)\n",
    "        conv = self.activation(conv)\n",
    "        conv = self.conv_2(conv)\n",
    "        conv = self.activation(conv)\n",
    "\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydOi-s0iNICX"
   },
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T17:45:13.266386Z",
     "iopub.status.busy": "2025-10-25T17:45:13.266086Z",
     "iopub.status.idle": "2025-10-25T17:45:13.282829Z",
     "shell.execute_reply": "2025-10-25T17:45:13.282023Z",
     "shell.execute_reply.started": "2025-10-25T17:45:13.266358Z"
    },
    "id": "vBsy5D5H6X2u",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, n_filters=64, n_classes=19):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = conv_block(in_ch, n_filters, dropout_prob=0, max_pooling=True)\n",
    "        self.conv_layer_2 = conv_block(n_filters, n_filters*2, dropout_prob=0, max_pooling=True)\n",
    "        self.conv_layer_3 = conv_block(n_filters*2, n_filters*4, dropout_prob=0, max_pooling=True)\n",
    "        self.conv_layer_4 = conv_block(n_filters*4, n_filters*8, dropout_prob=0.3, max_pooling=True)\n",
    "        self.conv_layer_5 = conv_block(n_filters*8, n_filters*16, dropout_prob=0.3, max_pooling=False)\n",
    "\n",
    "        self.upsample_layer_1 = upsampling_block(n_filters*16, n_filters*8, n_filters*8)\n",
    "        self.upsample_layer_2 = upsampling_block(n_filters*8, n_filters*4, n_filters*4)\n",
    "        self.upsample_layer_3 = upsampling_block(n_filters*4, n_filters*2, n_filters*2)\n",
    "        self.upsample_layer_4 = upsampling_block(n_filters*2, n_filters, n_filters)\n",
    "\n",
    "        self.last_conv = nn.Sequential(\n",
    "            nn.Conv2d(n_filters, n_filters, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_filters, n_classes, kernel_size=1, padding='same')\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_1_next, conv_1_skip = self.conv_layer_1(x)\n",
    "        conv_2_next, conv_2_skip = self.conv_layer_2(conv_1_next)\n",
    "        conv_3_next, conv_3_skip = self.conv_layer_3(conv_2_next)\n",
    "        conv_4_next, conv_4_skip = self.conv_layer_4(conv_3_next)\n",
    "        conv_5_next, conv_5_skip = self.conv_layer_5(conv_4_next)\n",
    "\n",
    "        out = self.upsample_layer_1(conv_5_next, conv_4_skip)\n",
    "        out = self.upsample_layer_2(out, conv_3_skip)\n",
    "        out = self.upsample_layer_3(out, conv_2_skip)\n",
    "        out = self.upsample_layer_4(out, conv_1_skip)\n",
    "        out = self.last_conv(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-25T17:45:51.193624Z",
     "iopub.status.busy": "2025-10-25T17:45:51.193334Z",
     "iopub.status.idle": "2025-10-25T17:45:52.061758Z",
     "shell.execute_reply": "2025-10-25T17:45:52.060992Z",
     "shell.execute_reply.started": "2025-10-25T17:45:51.193603Z"
    },
    "executionInfo": {
     "elapsed": 1996,
     "status": "ok",
     "timestamp": 1761237831352,
     "user": {
      "displayName": "Lorenzo Bacchini",
      "userId": "02263551721512258842"
     },
     "user_tz": -120
    },
    "id": "-pyGPJmM8Ypb",
    "outputId": "93b15290-8823-4ce5-aa20-5f9cc0bec043",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "unet = UNet().to(device)\n",
    "\n",
    "# Printing the model architecture and number of parameters\n",
    "summary(unet, (3, 128, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:14:19.358781Z",
     "iopub.status.busy": "2025-10-25T20:14:19.357922Z",
     "iopub.status.idle": "2025-10-25T20:14:19.364825Z",
     "shell.execute_reply": "2025-10-25T20:14:19.364032Z",
     "shell.execute_reply.started": "2025-10-25T20:14:19.358742Z"
    },
    "id": "WeyJLxEe6EfA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Transform definition to preprocess data before passing them through the model\n",
    "image_transforms = transforms.Compose([\n",
    "            transforms.Resize((128, 256), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x[0:3])\n",
    "])\n",
    "\n",
    "mask_transforms = transforms.Compose([\n",
    "            transforms.Resize((128, 256), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "            # we cannot use ToTensor() to transform the mask to tensor because we want to keep the\n",
    "            # mask values integer\n",
    "            transforms.Lambda(lambda x: torch.tensor(np.array(x)).long())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrwp05PnmVzh"
   },
   "source": [
    "# Net parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:14:21.671235Z",
     "iopub.status.busy": "2025-10-25T20:14:21.670708Z",
     "iopub.status.idle": "2025-10-25T20:14:21.674812Z",
     "shell.execute_reply": "2025-10-25T20:14:21.674144Z",
     "shell.execute_reply.started": "2025-10-25T20:14:21.671209Z"
    },
    "id": "gExP_sTp3TFa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters definition\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:10:20.455045Z",
     "iopub.status.busy": "2025-10-25T18:10:20.454373Z",
     "iopub.status.idle": "2025-10-25T18:10:20.458728Z",
     "shell.execute_reply": "2025-10-25T18:10:20.457935Z",
     "shell.execute_reply.started": "2025-10-25T18:10:20.455021Z"
    },
    "id": "KaEJa0K0Al5i",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loss function definition,\n",
    "the mask values put to 255 (void regions) are ingored so they do not contribute to the wights update,\n",
    "doing so the net will not learn to infer 255 mask values in new images\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:10:20.858521Z",
     "iopub.status.busy": "2025-10-25T18:10:20.858259Z",
     "iopub.status.idle": "2025-10-25T18:10:20.862546Z",
     "shell.execute_reply": "2025-10-25T18:10:20.861746Z",
     "shell.execute_reply.started": "2025-10-25T18:10:20.858503Z"
    },
    "id": "uYWQlKHJAzKP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optimizer definition\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGNKZGXqNICg"
   },
   "source": [
    "# Train dataset implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:10:22.978266Z",
     "iopub.status.busy": "2025-10-25T18:10:22.978001Z",
     "iopub.status.idle": "2025-10-25T18:10:23.455353Z",
     "shell.execute_reply": "2025-10-25T18:10:23.454442Z",
     "shell.execute_reply.started": "2025-10-25T18:10:22.978248Z"
    },
    "id": "6CZh3Vogcl1d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Definition of the dataset used to train the model\n",
    "dataset_train = CityscapeDataset(root_path=\"/kaggle/input/cityscape-dataset\", test=False, image_transform=image_transforms, mask_transform=mask_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:10:23.456958Z",
     "iopub.status.busy": "2025-10-25T18:10:23.456646Z",
     "iopub.status.idle": "2025-10-25T18:10:23.463357Z",
     "shell.execute_reply": "2025-10-25T18:10:23.462542Z",
     "shell.execute_reply.started": "2025-10-25T18:10:23.456929Z"
    },
    "id": "PbyaNkIc_hQw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Definition of the dataloader to iteratively load the images/masks from the train dataset\n",
    "dataloader_train = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJLnQRKkNICi"
   },
   "source": [
    "## Train dataset example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "execution": {
     "iopub.execute_input": "2025-10-25T17:46:32.392837Z",
     "iopub.status.busy": "2025-10-25T17:46:32.392126Z",
     "iopub.status.idle": "2025-10-25T17:46:43.099874Z",
     "shell.execute_reply": "2025-10-25T17:46:43.099084Z",
     "shell.execute_reply.started": "2025-10-25T17:46:32.392813Z"
    },
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1761237955286,
     "user": {
      "displayName": "Lorenzo Bacchini",
      "userId": "02263551721512258842"
     },
     "user_tz": -120
    },
    "id": "E9kkEjQNqf9U",
    "outputId": "20906570-7a03-4b29-bacb-5d3bbc1be840",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "img, coloured_mask, labelId_mask, = next(iter(dataloader_train))\n",
    "# Since img is a torch tensor (C, H, W) we have to permute its dimensions -> (H, W, C) before printing it\n",
    "img1_np = img[0].permute(1, 2, 0).numpy()\n",
    "img2_np = coloured_mask[0].numpy()\n",
    "img3_np = labelId_mask[0].numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img1_np)\n",
    "plt.title(\"img\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img2_np)\n",
    "plt.title(\"coloured mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img3_np, cmap='gray')\n",
    "plt.title(\"labelId mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtXbyMcEmjDg"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2025-10-25T18:10:31.352826Z",
     "iopub.status.busy": "2025-10-25T18:10:31.352525Z",
     "iopub.status.idle": "2025-10-25T19:15:19.848005Z",
     "shell.execute_reply": "2025-10-25T19:15:19.847080Z",
     "shell.execute_reply.started": "2025-10-25T18:10:31.352798Z"
    },
    "id": "bJnJkubWmiMf",
    "outputId": "997d3223-b0d9-4a72-cc98-33d95d129598",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "unet.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_losses = []\n",
    "    for i, batch in enumerate(dataloader_train):\n",
    "        images = batch[0].to(device)\n",
    "        # We use the labelIds_mask to train the network, not the coloured_mask\n",
    "        labelIds_mask = batch[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = unet(images)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labelIds_mask)\n",
    "        epoch_losses.append(loss.item() * images.size(0))\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        print(f'EPOCH#{epoch},\\t Batch#{i},\\t Loss:{loss.item()}')\n",
    "    losses.append(np.mean(epoch_losses) / len(dataloader_train.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T19:41:07.390379Z",
     "iopub.status.busy": "2025-10-25T19:41:07.389993Z",
     "iopub.status.idle": "2025-10-25T19:41:07.547142Z",
     "shell.execute_reply": "2025-10-25T19:41:07.546351Z",
     "shell.execute_reply.started": "2025-10-25T19:41:07.390354Z"
    },
    "id": "OiqTMZcqNICl",
    "outputId": "30a2e10f-a4a0-4916-c744-84afdb8025a6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot to see the evolution of the loss during the training\n",
    "print(losses)\n",
    "plt.plot(np.arange(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:07:16.447884Z",
     "iopub.status.busy": "2025-10-25T20:07:16.447055Z",
     "iopub.status.idle": "2025-10-25T20:07:16.659676Z",
     "shell.execute_reply": "2025-10-25T20:07:16.659062Z",
     "shell.execute_reply.started": "2025-10-25T20:07:16.447858Z"
    },
    "id": "URywpzXSNICm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "PATH = '/kaggle/working/U-Net-Cityscapes_3.pth'\n",
    "torch.save(unet.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T17:33:09.237595Z",
     "iopub.status.busy": "2025-10-25T17:33:09.237028Z",
     "iopub.status.idle": "2025-10-25T17:33:10.302769Z",
     "shell.execute_reply": "2025-10-25T17:33:10.301370Z",
     "shell.execute_reply.started": "2025-10-25T17:33:09.237559Z"
    },
    "id": "fqRhgQfYNICm",
    "outputId": "6150f750-9449-4a0e-cf55-e0a538f84959",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "PATH = '/kaggle/input/u-net-cityscapes-1/pytorch/default/1/U-Net-Cityscapes_2.pth'\n",
    "unet.load_state_dict(torch.load(PATH, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gCyXRJ4NICm"
   },
   "source": [
    "# Test dataset implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:07:49.981530Z",
     "iopub.status.busy": "2025-10-25T20:07:49.980849Z",
     "iopub.status.idle": "2025-10-25T20:08:03.580399Z",
     "shell.execute_reply": "2025-10-25T20:08:03.579821Z",
     "shell.execute_reply.started": "2025-10-25T20:07:49.981498Z"
    },
    "id": "sJCOoGh-NICn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Definition of the dataset used to test the model\n",
    "dataset_test = CityscapeDataset(root_path=\"/kaggle/input/cityscape-dataset\", test=True, image_transform=image_transforms, mask_transform=mask_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:08:03.581783Z",
     "iopub.status.busy": "2025-10-25T20:08:03.581433Z",
     "iopub.status.idle": "2025-10-25T20:08:03.585712Z",
     "shell.execute_reply": "2025-10-25T20:08:03.584955Z",
     "shell.execute_reply.started": "2025-10-25T20:08:03.581764Z"
    },
    "id": "2Zk-FjOfNICn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Definition of the dataloader to iteratively load the images/masks from the test dataset\n",
    "dataloader_test = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mx9AZWyHNICo"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:08:03.586673Z",
     "iopub.status.busy": "2025-10-25T20:08:03.586411Z",
     "iopub.status.idle": "2025-10-25T20:08:03.601199Z",
     "shell.execute_reply": "2025-10-25T20:08:03.600609Z",
     "shell.execute_reply.started": "2025-10-25T20:08:03.586648Z"
    },
    "id": "8PnfA2DdNICo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to compute the Intersection over Union rate\n",
    "'''\n",
    "Takes as input:\n",
    "    preds: tensor [B, C, H, W] -> output raw logits of the model\n",
    "    targets: tensor [B, H, W] -> ground truth (trainId)\n",
    "    num_classes: number of classes (e.g. 19 for Cityscapes)\n",
    "    ignore_index: value to be ingored in the grounf truth targets (es. 255)\n",
    "'''\n",
    "def compute_iou_torch(preds, targets, num_classes=19, ignore_index=255):\n",
    "    # Conversion from logits to classes\n",
    "    preds = torch.argmax(preds, dim=1)  # [B, H, W]\n",
    "\n",
    "    # Crafting the mask to ignore the 255 values\n",
    "    mask = targets != ignore_index\n",
    "    preds = preds[mask]\n",
    "    targets = targets[mask]\n",
    "\n",
    "    iou_per_class = torch.zeros(num_classes, device=preds.device)\n",
    "    for c in range(num_classes):\n",
    "        pred_c = preds == c\n",
    "        target_c = targets == c\n",
    "\n",
    "        intersection = (pred_c & target_c).sum().float()\n",
    "        union = (pred_c | target_c).sum().float()\n",
    "\n",
    "        # If the union == 0 then we ignore this result in the final iou computation\n",
    "        if union == 0:\n",
    "            iou_per_class[c] = torch.nan\n",
    "        else:\n",
    "            iou_per_class[c] = intersection / union\n",
    "\n",
    "    mean_iou = torch.nanmean(iou_per_class)\n",
    "\n",
    "    return iou_per_class, mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:08:12.557081Z",
     "iopub.status.busy": "2025-10-25T20:08:12.556841Z",
     "iopub.status.idle": "2025-10-25T20:11:23.938993Z",
     "shell.execute_reply": "2025-10-25T20:11:23.938091Z",
     "shell.execute_reply.started": "2025-10-25T20:08:12.557064Z"
    },
    "id": "Ohb1P-jNNICq",
    "outputId": "4cc02786-12f2-481b-c20f-0d7b5f3389c9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unet.eval()\n",
    "total_iou = torch.zeros(19).to(device)\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _, labels in tqdm(dataloader_test, desc=\"IoU\", total=len(dataloader_test), unit=\"batch\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = unet(images)\n",
    "        iou_per_class, mean_iou = compute_iou_torch(outputs, labels)\n",
    "\n",
    "        total_iou += torch.nan_to_num(iou_per_class)\n",
    "        num_batches += 1\n",
    "\n",
    "mean_iou_final = (total_iou / num_batches).mean()\n",
    "print(f\"Final mean IoU: {mean_iou_final.item():.4f}\")\n",
    "for i, iou in enumerate(iou_per_class):\n",
    "    print(f\"Class {i:02d} → IoU = {iou.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsgWGPx3NICq"
   },
   "source": [
    "# Visual Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:14:30.167137Z",
     "iopub.status.busy": "2025-10-25T20:14:30.166496Z",
     "iopub.status.idle": "2025-10-25T20:14:30.173141Z",
     "shell.execute_reply": "2025-10-25T20:14:30.172078Z",
     "shell.execute_reply.started": "2025-10-25T20:14:30.167114Z"
    },
    "id": "-I9Ve8hYNICs",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cytiscapes color map for the 19 classes (trainId)\n",
    "trainId2label = {\n",
    "     0:  (\"road\", (128, 64,128)),\n",
    "     1:  (\"sidewalk\", (244, 35,232)),\n",
    "     2:  (\"building\", (70, 70, 70)),\n",
    "     3:  (\"wall\", (102,102,156)),\n",
    "     4:  (\"fence\", (190,153,153)),\n",
    "     5:  (\"pole\", (153,153,153)),\n",
    "     6:  (\"traffic light\", (250,170, 30)),\n",
    "     7:  (\"traffic sign\", (220,220,  0)),\n",
    "     8:  (\"vegetation\", (107,142, 35)),\n",
    "     9:  (\"terrain\", (152,251,152)),\n",
    "    10: (\"sky\", (70,130,180)),\n",
    "    11: (\"person\", (220, 20, 60)),\n",
    "    12: (\"rider\", (255,  0,  0)),\n",
    "    13: (\"car\", (0,  0,142)),\n",
    "    14: (\"truck\", (0,  0, 70)),\n",
    "    15: (\"bus\", (0, 60,100)),\n",
    "    16: (\"train\", (0, 80,100)),\n",
    "    17: (\"motorcycle\", (0,  0,230)),\n",
    "    18: (\"bicycle\", (119, 11, 32))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:14:32.574087Z",
     "iopub.status.busy": "2025-10-25T20:14:32.573817Z",
     "iopub.status.idle": "2025-10-25T20:14:32.579280Z",
     "shell.execute_reply": "2025-10-25T20:14:32.578714Z",
     "shell.execute_reply.started": "2025-10-25T20:14:32.574067Z"
    },
    "id": "hHnbpvEoNICt",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to convert the grayscale labelIds to an rgb image in order to be compared\n",
    "to the coloured ground truth mask\n",
    "Input:\n",
    "        mask: torch.Tensor [H, W] or np.ndarray [H, W]\n",
    "    Output:\n",
    "        color_mask: np.ndarray [H, W, 3] (uint8)\n",
    "'''\n",
    "def colorize_mask(mask):\n",
    "    if torch.is_tensor(mask):\n",
    "        mask = mask.cpu().numpy()\n",
    "\n",
    "    color_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for train_id, (label_name, color) in trainId2label.items():\n",
    "        color_mask[mask == train_id] = color\n",
    "\n",
    "    return color_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:14:34.255668Z",
     "iopub.status.busy": "2025-10-25T20:14:34.255377Z",
     "iopub.status.idle": "2025-10-25T20:14:34.260363Z",
     "shell.execute_reply": "2025-10-25T20:14:34.259700Z",
     "shell.execute_reply.started": "2025-10-25T20:14:34.255647Z"
    },
    "id": "OAFY6T8BNICu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to print in the same plot three different images\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        if(i in (1,2)):\n",
    "            plt.imshow(display_list[i])\n",
    "        else:\n",
    "            plt.imshow(display_list[i].permute(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:14:35.563957Z",
     "iopub.status.busy": "2025-10-25T20:14:35.563687Z",
     "iopub.status.idle": "2025-10-25T20:14:35.567891Z",
     "shell.execute_reply": "2025-10-25T20:14:35.567167Z",
     "shell.execute_reply.started": "2025-10-25T20:14:35.563936Z"
    },
    "id": "BPlXTtuvm0ik",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function that converts the logits to the actual classes\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = torch.argmax(pred_mask, dim=1).detach()\n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:14:36.439569Z",
     "iopub.status.busy": "2025-10-25T20:14:36.438973Z",
     "iopub.status.idle": "2025-10-25T20:14:36.444978Z",
     "shell.execute_reply": "2025-10-25T20:14:36.444291Z",
     "shell.execute_reply.started": "2025-10-25T20:14:36.439545Z"
    },
    "id": "n-FQXjRDNICv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function that displays the first image of each of the num batches\n",
    "def show_predictions(dataloader, device, num=1):\n",
    "    unet.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # RGB image\n",
    "            IMG = batch[0][0, :, : ,:].to(device).unsqueeze(0)\n",
    "            # Coloured mask\n",
    "            MASK = batch[1][0, :, :, :].to(device).unsqueeze(0)\n",
    "            # LabelIds prediction\n",
    "            pred_mask = unet.to(device)(IMG)\n",
    "            # Plotting the three images next to each other\n",
    "            display([IMG[0].cpu(), MASK[0].cpu(), colorize_mask(create_mask(pred_mask).cpu()[0])]).show()\n",
    "\n",
    "            if i >= num:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:14:38.820006Z",
     "iopub.status.busy": "2025-10-25T20:14:38.819338Z",
     "iopub.status.idle": "2025-10-25T20:14:59.320367Z",
     "shell.execute_reply": "2025-10-25T20:14:59.319196Z",
     "shell.execute_reply.started": "2025-10-25T20:14:38.819979Z"
    },
    "id": "PiVcqmKVNICw",
    "outputId": "0f764225-e3d1-4e3c-a474-95400bec6f0a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Showing n random images from the test dataset with the ground truth mask and the predicted mask\n",
    "show_predictions(dataloader_test, device, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T20:15:14.339096Z",
     "iopub.status.busy": "2025-10-25T20:15:14.338844Z",
     "iopub.status.idle": "2025-10-25T20:15:14.471338Z",
     "shell.execute_reply": "2025-10-25T20:15:14.470730Z",
     "shell.execute_reply.started": "2025-10-25T20:15:14.339079Z"
    },
    "id": "WzJRijwhNICy",
    "outputId": "994cbd23-0938-4536-9e9d-8c75d804c8e8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Crea figura\n",
    "fig, ax = plt.subplots(figsize=(6, 8))\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, len(trainId2label))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Disegna rettangolini colorati con testo accanto\n",
    "for i, (train_id, (name, color)) in enumerate(trainId2label.items()):\n",
    "    y = len(trainId2label) - i - 1\n",
    "    rgb = np.array(color) / 255.0  # normalizza per matplotlib\n",
    "    ax.add_patch(plt.Rectangle((0, y), 1, 1, color=rgb))\n",
    "    ax.text(1.5, y + 0.3, f\"{train_id:2d}: {name}\", fontsize=10, va=\"center\")\n",
    "\n",
    "plt.title(\"Cityscapes – 19 Classi (trainId + colore)\", fontsize=12, pad=10)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8346584,
     "sourceId": 13189886,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 481224,
     "modelInstanceId": 465390,
     "sourceId": 618845,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 481565,
     "modelInstanceId": 465741,
     "sourceId": 619257,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
